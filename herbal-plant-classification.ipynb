{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":6417582,"sourceType":"datasetVersion","datasetId":3701557},{"sourceId":6675703,"sourceType":"datasetVersion","datasetId":3851533}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-12-23T15:55:57.286464Z","iopub.execute_input":"2024-12-23T15:55:57.286708Z","iopub.status.idle":"2024-12-23T15:56:09.831833Z","shell.execute_reply.started":"2024-12-23T15:55:57.286680Z","shell.execute_reply":"2024-12-23T15:56:09.831053Z"},"trusted":true},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1734969362.699685      13 common_lib.cc:815] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=local.\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:531\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Convert Images in directory into Dataset\nwe can use `tf.keras.preprocessing.image_dataset_from_directory` to convert the data into dataset so we can train the models out of the box","metadata":{}},{"cell_type":"code","source":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    \"/kaggle/input/indian-medicinal-leaves-dataset/Indian Medicinal Leaves Image Datasets/Medicinal Leaf dataset\",\n    shuffle=True,\n    batch_size=32,\n    image_size=(299, 299),\n)\n\nlabels = dataset.class_names\nlabels","metadata":{"execution":{"iopub.status.busy":"2024-12-23T15:59:42.111090Z","iopub.execute_input":"2024-12-23T15:59:42.111506Z","iopub.status.idle":"2024-12-23T15:59:47.036643Z","shell.execute_reply.started":"2024-12-23T15:59:42.111473Z","shell.execute_reply":"2024-12-23T15:59:47.035906Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Found 6900 files belonging to 80 classes.\n","output_type":"stream"},{"name":"stderr","text":"2024-12-23 15:59:46.968900: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.969000: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.969074: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.969162: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.969244: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.969442: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.969558: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.969638: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.969717: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.969796: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.970002: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.970163: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.970250: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.970332: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.970422: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.970627: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.970714: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.970799: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.970901: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.970975: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.971169: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.971261: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.971348: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.971428: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.971521: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.971769: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.971857: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.971932: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.972024: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.972110: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.972362: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.972449: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.972530: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.972635: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.972728: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.972978: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.973066: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.973212: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.973310: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2024-12-23 15:59:46.973396: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['Aloevera',\n 'Amla',\n 'Amruthaballi',\n 'Arali',\n 'Astma_weed',\n 'Badipala',\n 'Balloon_Vine',\n 'Bamboo',\n 'Beans',\n 'Betel',\n 'Bhrami',\n 'Bringaraja',\n 'Caricature',\n 'Castor',\n 'Catharanthus',\n 'Chakte',\n 'Chilly',\n 'Citron lime (herelikai)',\n 'Coffee',\n 'Common rue(naagdalli)',\n 'Coriender',\n 'Curry',\n 'Doddpathre',\n 'Drumstick',\n 'Ekka',\n 'Eucalyptus',\n 'Ganigale',\n 'Ganike',\n 'Gasagase',\n 'Ginger',\n 'Globe Amarnath',\n 'Guava',\n 'Henna',\n 'Hibiscus',\n 'Honge',\n 'Insulin',\n 'Jackfruit',\n 'Jasmine',\n 'Kambajala',\n 'Kasambruga',\n 'Kohlrabi',\n 'Lantana',\n 'Lemon',\n 'Lemongrass',\n 'Malabar_Nut',\n 'Malabar_Spinach',\n 'Mango',\n 'Marigold',\n 'Mint',\n 'Neem',\n 'Nelavembu',\n 'Nerale',\n 'Nooni',\n 'Onion',\n 'Padri',\n 'Palak(Spinach)',\n 'Papaya',\n 'Parijatha',\n 'Pea',\n 'Pepper',\n 'Pomoegranate',\n 'Pumpkin',\n 'Raddish',\n 'Rose',\n 'Sampige',\n 'Sapota',\n 'Seethaashoka',\n 'Seethapala',\n 'Spinach1',\n 'Tamarind',\n 'Taro',\n 'Tecoma',\n 'Thumbe',\n 'Tomato',\n 'Tulsi',\n 'Turmeric',\n 'ashoka',\n 'camphor',\n 'kamakasturi',\n 'kepala']"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\n\nfor image_batch, labels_batch in dataset.take(1):\n    print(image_batch.shape)\n    print(labels_batch.numpy())\n    break","metadata":{"execution":{"iopub.status.busy":"2024-12-23T16:00:01.769319Z","iopub.execute_input":"2024-12-23T16:00:01.769634Z","iopub.status.idle":"2024-12-23T16:00:02.590226Z","shell.execute_reply.started":"2024-12-23T16:00:01.769606Z","shell.execute_reply":"2024-12-23T16:00:02.589381Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(32, 299, 299, 3)\n[69 76 55 19 55 13  3 11 21 42  0 45 51 69 29 48  3 34 45 69 40  3  2  7\n 54 75 64 24 74 20 52 14]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# train test split\ntrain_size = int(0.8 * len(dataset))\ntest_size = int(0.2 * len(dataset))\ntrain_size, test_size","metadata":{"execution":{"iopub.status.busy":"2024-12-23T16:00:02.591620Z","iopub.execute_input":"2024-12-23T16:00:02.591982Z","iopub.status.idle":"2024-12-23T16:00:02.597848Z","shell.execute_reply.started":"2024-12-23T16:00:02.591949Z","shell.execute_reply":"2024-12-23T16:00:02.597112Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(172, 43)"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Train, Test, Validate\npartition the data into train test and validation datasets","metadata":{}},{"cell_type":"code","source":"def get_dataset_partisions_tf(ds, train_split=0.8, test_split=0.2, shuffle=True, shuffle_size=10000):\n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed=12)\n    train_size = int(train_split * len(ds))\n    test_size = int(test_split * len(ds))\n    train_ds = ds.take(train_size)\n    test_ds = ds.skip(train_size)\n    val_ds = test_ds.skip(test_size)\n    test_ds = test_ds.take(test_size)\n    return train_ds, test_ds, val_ds","metadata":{"execution":{"iopub.status.busy":"2024-12-23T16:00:06.038238Z","iopub.execute_input":"2024-12-23T16:00:06.039022Z","iopub.status.idle":"2024-12-23T16:00:06.043727Z","shell.execute_reply.started":"2024-12-23T16:00:06.038986Z","shell.execute_reply":"2024-12-23T16:00:06.042875Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_ds, test_ds, val_ds = get_dataset_partisions_tf(dataset)\nlen(train_ds), len(test_ds), len(val_ds)","metadata":{"execution":{"iopub.status.busy":"2024-12-23T16:00:06.756413Z","iopub.execute_input":"2024-12-23T16:00:06.756737Z","iopub.status.idle":"2024-12-23T16:00:06.764188Z","shell.execute_reply.started":"2024-12-23T16:00:06.756708Z","shell.execute_reply":"2024-12-23T16:00:06.763443Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(172, 43, 1)"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## Resize and Normalize\n- Xception models takes the image input as 299x299 pixels so converting into the trainable format is necessary\n- The Images are to be normalized before to train accurately and efficiently","metadata":{}},{"cell_type":"code","source":"resize_and_rescale = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.Resizing(299, 299),\n    tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n])","metadata":{"execution":{"iopub.status.busy":"2024-12-23T16:00:09.648770Z","iopub.execute_input":"2024-12-23T16:00:09.649484Z","iopub.status.idle":"2024-12-23T16:00:09.657203Z","shell.execute_reply.started":"2024-12-23T16:00:09.649448Z","shell.execute_reply":"2024-12-23T16:00:09.656500Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### Download the Xception model predefined weights from tensorflow into your working environment","metadata":{}},{"cell_type":"code","source":"# train using Xception\nbase_model = tf.keras.applications.Xception(\n    weights='imagenet',\n    input_shape=(299, 299, 3),\n    include_top=False,\n    pooling='avg',\n    classifier_activation='softmax',\n    classes=len(labels)\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-23T16:00:11.161276Z","iopub.execute_input":"2024-12-23T16:00:11.162157Z","iopub.status.idle":"2024-12-23T16:00:13.141750Z","shell.execute_reply.started":"2024-12-23T16:00:11.162120Z","shell.execute_reply":"2024-12-23T16:00:13.140902Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83683744/83683744 [==============================] - 0s 0us/step\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"base_model.trainable = False\n\ninputs = tf.keras.Input(shape=(299, 299, 3))\nx = resize_and_rescale(inputs)\nx = base_model(x, training=False)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = tf.keras.layers.Dense(len(labels), activation='softmax')(x)\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    batch_size=32,\n    epochs=25\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-23T16:00:13.143125Z","iopub.execute_input":"2024-12-23T16:00:13.143419Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 299, 299, 3)]     0         \n                                                                 \n sequential_1 (Sequential)   (None, 299, 299, 3)       0         \n                                                                 \n xception (Functional)       (None, 2048)              20861480  \n                                                                 \n dense (Dense)               (None, 128)               262272    \n                                                                 \n dropout (Dropout)           (None, 128)               0         \n                                                                 \n dense_1 (Dense)             (None, 80)                10320     \n                                                                 \n=================================================================\nTotal params: 21134072 (80.62 MB)\nTrainable params: 272592 (1.04 MB)\nNon-trainable params: 20861480 (79.58 MB)\n_________________________________________________________________\nEpoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: premature end of data segment\nCorrupt JPEG data: 445 extraneous bytes before marker 0xd9\nCorrupt JPEG data: premature end of data segment\n","output_type":"stream"},{"name":"stdout","text":"172/172 [==============================] - ETA: 0s - loss: 3.3724 - accuracy: 0.2170","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: premature end of data segment\nCorrupt JPEG data: 445 extraneous bytes before marker 0xd9\nCorrupt JPEG data: premature end of data segment\n","output_type":"stream"},{"name":"stdout","text":"172/172 [==============================] - 236s 1s/step - loss: 3.3724 - accuracy: 0.2170 - val_loss: 1.9661 - val_accuracy: 0.6250\nEpoch 2/25\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: premature end of data segment\nCorrupt JPEG data: 445 extraneous bytes before marker 0xd9\nCorrupt JPEG data: premature end of data segment\n","output_type":"stream"},{"name":"stdout","text":"172/172 [==============================] - ETA: 0s - loss: 1.9703 - accuracy: 0.5055","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: premature end of data segment\nCorrupt JPEG data: 445 extraneous bytes before marker 0xd9\nCorrupt JPEG data: premature end of data segment\n","output_type":"stream"},{"name":"stdout","text":"172/172 [==============================] - 241s 1s/step - loss: 1.9703 - accuracy: 0.5055 - val_loss: 1.5473 - val_accuracy: 0.5625\nEpoch 3/25\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: premature end of data segment\nCorrupt JPEG data: premature end of data segment\nCorrupt JPEG data: 445 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"name":"stdout","text":"172/172 [==============================] - ETA: 0s - loss: 1.3982 - accuracy: 0.6400","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: premature end of data segment\nCorrupt JPEG data: 445 extraneous bytes before marker 0xd9\nCorrupt JPEG data: premature end of data segment\n","output_type":"stream"},{"name":"stdout","text":"172/172 [==============================] - 235s 1s/step - loss: 1.3982 - accuracy: 0.6400 - val_loss: 1.2727 - val_accuracy: 0.7188\nEpoch 4/25\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: premature end of data segment\nCorrupt JPEG data: premature end of data segment\nCorrupt JPEG data: 445 extraneous bytes before marker 0xd9\n","output_type":"stream"},{"name":"stdout","text":"172/172 [==============================] - ETA: 0s - loss: 1.0976 - accuracy: 0.7225","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: premature end of data segment\nCorrupt JPEG data: 445 extraneous bytes before marker 0xd9\nCorrupt JPEG data: premature end of data segment\n","output_type":"stream"},{"name":"stdout","text":"172/172 [==============================] - 233s 1s/step - loss: 1.0976 - accuracy: 0.7225 - val_loss: 0.6914 - val_accuracy: 0.8438\nEpoch 5/25\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: premature end of data segment\nCorrupt JPEG data: 445 extraneous bytes before marker 0xd9\nCorrupt JPEG data: premature end of data segment\n","output_type":"stream"},{"name":"stdout","text":" 70/172 [===========>..................] - ETA: 2:02 - loss: 0.9150 - accuracy: 0.7648","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model.evaluate(test_ds)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# predict with new images\nimport numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/alo.jpg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\n\n\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# predict with new images\nimport numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/bamboo.jpeg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/betel-leaf-1024x1024.jpg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/bamboo.jpeg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/doddapatre.jpg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/tulsi-leaves-t-cut-500x500.jpg.webp', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plot accuracy and loss\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\n\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('model_avg_25.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}